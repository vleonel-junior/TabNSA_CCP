{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69685d53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T19:01:27.820193Z",
     "iopub.status.busy": "2025-06-20T19:01:27.819691Z",
     "iopub.status.idle": "2025-06-20T19:01:28.937469Z",
     "shell.execute_reply": "2025-06-20T19:01:28.936476Z"
    },
    "papermill": {
     "duration": 1.122,
     "end_time": "2025-06-20T19:01:28.938882",
     "exception": false,
     "start_time": "2025-06-20T19:01:27.816882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'TabNSA_CCP'...\r\n",
      "remote: Enumerating objects: 23, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (23/23), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\r\n",
      "remote: Total 23 (delta 5), reused 23 (delta 5), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (23/23), 432.66 KiB | 17.31 MiB/s, done.\r\n",
      "Resolving deltas: 100% (5/5), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/vleonel-junior/TabNSA_CCP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71c0ee2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T19:01:28.944188Z",
     "iopub.status.busy": "2025-06-20T19:01:28.943651Z",
     "iopub.status.idle": "2025-06-20T19:01:28.947697Z",
     "shell.execute_reply": "2025-06-20T19:01:28.947050Z"
    },
    "papermill": {
     "duration": 0.00785,
     "end_time": "2025-06-20T19:01:28.948978",
     "exception": false,
     "start_time": "2025-06-20T19:01:28.941128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/working/TabNSA_CCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8626e02d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T19:01:28.955122Z",
     "iopub.status.busy": "2025-06-20T19:01:28.954854Z",
     "iopub.status.idle": "2025-06-20T19:01:29.298937Z",
     "shell.execute_reply": "2025-06-20T19:01:29.298059Z"
    },
    "papermill": {
     "duration": 0.348804,
     "end_time": "2025-06-20T19:01:29.300414",
     "exception": false,
     "start_time": "2025-06-20T19:01:28.951610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/TabNSA_CCP\r\n",
      "total 28\r\n",
      "drwxr-xr-x 4 root root  4096 Jun 20 19:01 .\r\n",
      "drwxr-xr-x 3 root root  4096 Jun 20 19:01 ..\r\n",
      "drwxr-xr-x 4 root root  4096 Jun 20 19:01 data\r\n",
      "drwxr-xr-x 8 root root  4096 Jun 20 19:01 .git\r\n",
      "-rw-r--r-- 1 root root 12268 Jun 20 19:01 TabNSA-BinClass.py\r\n",
      "total 16\r\n",
      "drwxr-xr-x 4 root root 4096 Jun 20 19:01 .\r\n",
      "drwxr-xr-x 4 root root 4096 Jun 20 19:01 ..\r\n",
      "drwxr-xr-x 2 root root 4096 Jun 20 19:01 bank\r\n",
      "drwxr-xr-x 3 root root 4096 Jun 20 19:01 telecom\r\n"
     ]
    }
   ],
   "source": [
    "# Le bon chemin est directement :\n",
    "import os\n",
    "os.chdir('/kaggle/working/TabNSA_CCP')\n",
    "\n",
    "# Vérifier que vous êtes au bon endroit\n",
    "!pwd\n",
    "!ls -la\n",
    "\n",
    "# Vérifier que les datasets sont là\n",
    "!ls -la data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2eb186",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T19:01:29.307929Z",
     "iopub.status.busy": "2025-06-20T19:01:29.307714Z",
     "iopub.status.idle": "2025-06-20T19:02:48.125141Z",
     "shell.execute_reply": "2025-06-20T19:02:48.124366Z"
    },
    "papermill": {
     "duration": 78.822845,
     "end_time": "2025-06-20T19:02:48.126607",
     "exception": false,
     "start_time": "2025-06-20T19:01:29.303762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting native-sparse-attention-pytorch\r\n",
      "  Downloading native_sparse_attention_pytorch-0.2.2-py3-none-any.whl.metadata (4.8 kB)\r\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\r\n",
      "Requirement already satisfied: einops>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from native-sparse-attention-pytorch) (0.8.1)\r\n",
      "Collecting einx>=0.3.0 (from native-sparse-attention-pytorch)\r\n",
      "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\r\n",
      "Collecting jaxtyping (from native-sparse-attention-pytorch)\r\n",
      "  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Collecting local-attention>=1.11.1 (from native-sparse-attention-pytorch)\r\n",
      "  Downloading local_attention-1.11.1-py3-none-any.whl.metadata (907 bytes)\r\n",
      "Collecting rotary-embedding-torch (from native-sparse-attention-pytorch)\r\n",
      "  Downloading rotary_embedding_torch-0.8.6-py3-none-any.whl.metadata (675 bytes)\r\n",
      "Requirement already satisfied: torch>=2.5 in /usr/local/lib/python3.11/dist-packages (from native-sparse-attention-pytorch) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\r\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\r\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\r\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from einx>=0.3.0->native-sparse-attention-pytorch) (1.13.1)\r\n",
      "Requirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (from einx>=0.3.0->native-sparse-attention-pytorch) (2.4.6)\r\n",
      "Collecting hyper-connections>=0.1.8 (from local-attention>=1.11.1->native-sparse-attention-pytorch)\r\n",
      "  Downloading hyper_connections-0.2.1-py3-none-any.whl.metadata (6.0 kB)\r\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5->native-sparse-attention-pytorch) (3.18.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5->native-sparse-attention-pytorch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5->native-sparse-attention-pytorch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5->native-sparse-attention-pytorch) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5->native-sparse-attention-pytorch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5->native-sparse-attention-pytorch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5->native-sparse-attention-pytorch) (12.4.127)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.5->native-sparse-attention-pytorch)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.5->native-sparse-attention-pytorch)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.5->native-sparse-attention-pytorch)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.5->native-sparse-attention-pytorch)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.5->native-sparse-attention-pytorch)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.5->native-sparse-attention-pytorch)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5->native-sparse-attention-pytorch) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5->native-sparse-attention-pytorch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5->native-sparse-attention-pytorch) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.5->native-sparse-attention-pytorch)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5->native-sparse-attention-pytorch) (3.2.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->einx>=0.3.0->native-sparse-attention-pytorch) (1.3.0)\r\n",
      "Collecting wadler-lindig>=0.1.3 (from jaxtyping->native-sparse-attention-pytorch)\r\n",
      "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2.4.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5->native-sparse-attention-pytorch) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->optuna) (2024.2.0)\r\n",
      "Downloading native_sparse_attention_pytorch-0.2.2-py3-none-any.whl (27 kB)\r\n",
      "Downloading einx-0.3.0-py3-none-any.whl (102 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading local_attention-1.11.1-py3-none-any.whl (9.4 kB)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rotary_embedding_torch-0.8.6-py3-none-any.whl (5.6 kB)\r\n",
      "Downloading hyper_connections-0.2.1-py3-none-any.whl (16 kB)\r\n",
      "Downloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\r\n",
      "Installing collected packages: wadler-lindig, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jaxtyping, nvidia-cusolver-cu12, rotary-embedding-torch, hyper-connections, local-attention, einx, native-sparse-attention-pytorch\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\r\n",
      "Successfully installed einx-0.3.0 hyper-connections-0.2.1 jaxtyping-0.3.2 local-attention-1.11.1 native-sparse-attention-pytorch-0.2.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rotary-embedding-torch-0.8.6 wadler-lindig-0.1.7\r\n"
     ]
    }
   ],
   "source": [
    "!pip install native-sparse-attention-pytorch optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c4c99d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T19:02:48.165730Z",
     "iopub.status.busy": "2025-06-20T19:02:48.165050Z",
     "iopub.status.idle": "2025-06-20T19:30:46.151845Z",
     "shell.execute_reply": "2025-06-20T19:30:46.151066Z"
    },
    "papermill": {
     "duration": 1678.007833,
     "end_time": "2025-06-20T19:30:46.153410",
     "exception": false,
     "start_time": "2025-06-20T19:02:48.145577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets configurés:  ['telecom', 'bank']\r\n",
      "\r\n",
      "=== Traitement du dataset: telecom ===\r\n",
      "Forme des données X: (7043, 20)\r\n",
      "Forme des labels y: (7043,)\r\n",
      "Classes uniques: ['No' 'Yes']\r\n",
      "\u001b[32m[I 2025-06-20 19:03:03,248]\u001b[0m A new study created in memory with name: no-name-74fcbcdc-dee6-4c03-8d94-b571ef217761\u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:03:03,250]\u001b[0m Trial 0 pruned. \u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:04:26,827]\u001b[0m Trial 1 finished with value: 0.8078099838969404 and parameters: {'dim': 384, 'dim_head': 16, 'heads': 5, 'sliding_window_size': 4, 'compress_block_size': 8, 'selection_block_size': 20, 'num_selected_blocks': 1, 'learning_rate': 0.00014611845740116248, 'batch_size': 96}. Best is trial 1 with value: 0.8078099838969404.\u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:04:26,829]\u001b[0m Trial 2 pruned. \u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:06:44,845]\u001b[0m Trial 3 finished with value: 0.8307890499194848 and parameters: {'dim': 192, 'dim_head': 64, 'heads': 8, 'sliding_window_size': 5, 'compress_block_size': 4, 'selection_block_size': 8, 'num_selected_blocks': 2, 'learning_rate': 6.112323797066506e-05, 'batch_size': 96}. Best is trial 3 with value: 0.8307890499194848.\u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:09:15,619]\u001b[0m Trial 4 finished with value: 0.8324315619967795 and parameters: {'dim': 320, 'dim_head': 48, 'heads': 12, 'sliding_window_size': 3, 'compress_block_size': 16, 'selection_block_size': 24, 'num_selected_blocks': 4, 'learning_rate': 1.8252645625762334e-06, 'batch_size': 64}. Best is trial 4 with value: 0.8324315619967795.\u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:11:11,209]\u001b[0m Trial 5 finished with value: 0.7245732689210951 and parameters: {'dim': 192, 'dim_head': 64, 'heads': 7, 'sliding_window_size': 2, 'compress_block_size': 4, 'selection_block_size': 32, 'num_selected_blocks': 4, 'learning_rate': 3.111387931246465e-06, 'batch_size': 64}. Best is trial 4 with value: 0.8324315619967795.\u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:12:05,447]\u001b[0m Trial 6 finished with value: 0.74 and parameters: {'dim': 64, 'dim_head': 32, 'heads': 4, 'sliding_window_size': 6, 'compress_block_size': 12, 'selection_block_size': 24, 'num_selected_blocks': 1, 'learning_rate': 1.0885607674026544e-06, 'batch_size': 160}. Best is trial 4 with value: 0.8324315619967795.\u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:13:39,852]\u001b[0m Trial 7 finished with value: 0.8453945249597424 and parameters: {'dim': 64, 'dim_head': 16, 'heads': 11, 'sliding_window_size': 3, 'compress_block_size': 8, 'selection_block_size': 24, 'num_selected_blocks': 3, 'learning_rate': 0.009103791550088407, 'batch_size': 160}. Best is trial 7 with value: 0.8453945249597424.\u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:13:39,853]\u001b[0m Trial 8 pruned. \u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:13:39,854]\u001b[0m Trial 9 pruned. \u001b[0m\r\n",
      "Dataset: telecom\r\n",
      "Nombre de résultats: 1\r\n",
      "Meilleurs paramètres: {'dim': 64, 'dim_head': 16, 'heads': 11, 'sliding_window_size': 3, 'compress_block_size': 8, 'selection_block_size': 24, 'num_selected_blocks': 3, 'learning_rate': 0.009103791550088407, 'batch_size': 160}\r\n",
      "AUC moyen (top 10): 0.8165\r\n",
      "Meilleur AUC: 0.8165\r\n",
      "==================================================\r\n",
      "\r\n",
      "=== Traitement du dataset: bank ===\r\n",
      "Forme des données X: (10000, 10)\r\n",
      "Forme des labels y: (10000,)\r\n",
      "Classes uniques: [0 1]\r\n",
      "\u001b[32m[I 2025-06-20 19:15:24,684]\u001b[0m A new study created in memory with name: no-name-273dcbdc-9ff6-4303-9af6-9e0f655a71f4\u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:17:31,537]\u001b[0m Trial 0 finished with value: 0.7581936030665215 and parameters: {'dim': 128, 'dim_head': 96, 'heads': 8, 'sliding_window_size': 2, 'compress_block_size': 4, 'selection_block_size': 16, 'num_selected_blocks': 7, 'learning_rate': 2.213170886144485e-06, 'batch_size': 160}. Best is trial 0 with value: 0.7581936030665215.\u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:19:40,448]\u001b[0m Trial 1 finished with value: 0.7966744035981546 and parameters: {'dim': 128, 'dim_head': 96, 'heads': 8, 'sliding_window_size': 2, 'compress_block_size': 4, 'selection_block_size': 24, 'num_selected_blocks': 6, 'learning_rate': 0.0004488334459388304, 'batch_size': 160}. Best is trial 1 with value: 0.7966744035981546.\u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:19:40,449]\u001b[0m Trial 2 pruned. \u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:19:40,450]\u001b[0m Trial 3 pruned. \u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:19:40,451]\u001b[0m Trial 4 pruned. \u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:22:04,627]\u001b[0m Trial 5 finished with value: 0.8574125261241825 and parameters: {'dim': 320, 'dim_head': 80, 'heads': 7, 'sliding_window_size': 11, 'compress_block_size': 20, 'selection_block_size': 20, 'num_selected_blocks': 6, 'learning_rate': 7.480040464764397e-06, 'batch_size': 128}. Best is trial 5 with value: 0.8574125261241825.\u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:24:15,164]\u001b[0m Trial 6 finished with value: 0.8295884658724273 and parameters: {'dim': 384, 'dim_head': 16, 'heads': 11, 'sliding_window_size': 5, 'compress_block_size': 4, 'selection_block_size': 28, 'num_selected_blocks': 4, 'learning_rate': 2.3807932050534396e-05, 'batch_size': 128}. Best is trial 5 with value: 0.8574125261241825.\u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:26:19,291]\u001b[0m Trial 7 finished with value: 0.8250618794001792 and parameters: {'dim': 384, 'dim_head': 96, 'heads': 8, 'sliding_window_size': 6, 'compress_block_size': 12, 'selection_block_size': 24, 'num_selected_blocks': 5, 'learning_rate': 0.00031844974419314976, 'batch_size': 160}. Best is trial 5 with value: 0.8574125261241825.\u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:26:19,292]\u001b[0m Trial 8 pruned. \u001b[0m\r\n",
      "\u001b[32m[I 2025-06-20 19:28:04,927]\u001b[0m Trial 9 finished with value: 0.8441794839691421 and parameters: {'dim': 192, 'dim_head': 16, 'heads': 4, 'sliding_window_size': 7, 'compress_block_size': 4, 'selection_block_size': 16, 'num_selected_blocks': 2, 'learning_rate': 0.007331600527930811, 'batch_size': 96}. Best is trial 5 with value: 0.8574125261241825.\u001b[0m\r\n",
      "Dataset: bank\r\n",
      "Nombre de résultats: 1\r\n",
      "Meilleurs paramètres: {'dim': 320, 'dim_head': 80, 'heads': 7, 'sliding_window_size': 11, 'compress_block_size': 20, 'selection_block_size': 20, 'num_selected_blocks': 6, 'learning_rate': 7.480040464764397e-06, 'batch_size': 128}\r\n",
      "AUC moyen (top 10): 0.8694\r\n",
      "Meilleur AUC: 0.8694\r\n",
      "==================================================\r\n"
     ]
    }
   ],
   "source": [
    "# Sur Kaggle\n",
    "# import os\n",
    "# os.chdir('/kaggle/working/TabNSA_CCP')\n",
    "# !git pull origin main\n",
    "!python TabNSA-BinClass.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8223a6bf",
   "metadata": {
    "papermill": {
     "duration": 0.018018,
     "end_time": "2025-06-20T19:30:46.191202",
     "exception": false,
     "start_time": "2025-06-20T19:30:46.173184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1762.806576,
   "end_time": "2025-06-20T19:30:46.528899",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-20T19:01:23.722323",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
